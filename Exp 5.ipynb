{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please Run on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):  \n",
    "    return [token for token in corpus.split(' ') if token != '']\n",
    "def _conditional_prob(s, n): \n",
    "    return round(float(s.count(f'{n[0]} {n[1]}') / s.count(n[0])), 2)\n",
    "def get_conditional_prob(s, ngrams):\n",
    "    conditional_prob = {}\n",
    "    for ngram in ngrams:  conditional_prob[ngram] = _conditional_prob(s, ngram)\n",
    "    return conditional_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _emission_prob(s, t):  \n",
    "    return float(s.count(f'{t[0]}/{t[1]}') / s.count(t[0]))\n",
    "def get_emission_prob(s, tagged_corpus):\n",
    "    mat = [[0 for i in range(len(tokens))] for j in range(len(tokens))]; emission_prob = {}\n",
    "    for t in tagged_corpus: x = (t[1], t[0]);  emission_prob[x] = _emission_prob(s, t)\n",
    "    return emission_prob\n",
    "def get_n_grams(s, tokens, n=2):\n",
    "    s = s.lower(); s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s); ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return list(set([ngram for ngram in ngrams]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_corpus(corpus):\n",
    "    split = corpus.split(' ');  word_tag = [];  text = ''; tags = ''\n",
    "    for s in split:\n",
    "        word, tag = s.split('/');  word_tag.append((word, tag));  text = text + f'{word} ';  tags = tags + f'{tag} '\n",
    "    return text, tags, list(set(word_tag))\n",
    "def format_dict(prob):\n",
    "    format_prob = {};  keys = prob.keys()\n",
    "    for k in keys:    format_prob[k[0]] = {}\n",
    "    for k in keys:    format_prob[k[0]][k[1]] = prob[k]\n",
    "    return format_prob\n",
    "def get_start_prob(transition_prob):\n",
    "    start_prob = transition_prob['<start>']; del start_prob['<start>'];  return start_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': {'</end>': {'</end>': 0.0, '<start>': 0.5},\n",
      "       '<start>': {'dog': 1.0},\n",
      "       'cat': {'</end>': 0.5, 'cat': 0.5},\n",
      "       'dog': {'</end>': 0.25, 'cat': 0.25, 'dog': 0.25}},\n",
      " 'B': {'cat': {'meow': 0.5, 'woof': 0.25}, 'dog': {'meow': 0.5, 'woof': 0.75}},\n",
      " 'O': ['woof', 'meow'],\n",
      " 'Q': ['cat', 'dog', '<start>', '</end>'],\n",
      " 'q0': '<start>',\n",
      " 'qF': '</end>',\n",
      " 'start_prob': {'dog': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "with open('corpus1.txt', 'r') as f:    all_lines = f.readlines()\n",
    "corpus_tag = ' '.join([x.replace('\\n', '') for x in all_lines])\n",
    "tagged_corpus = [];  text = [];  tags = []\n",
    "for line in all_lines:\n",
    "    line = line.replace('\\n', ''); txt, tag, c = format_corpus(line);txt = txt[:len(txt)-1]; tag = tag[:len(tag)-1]\n",
    "    tag = f'<start> {tag} </end>'; text.append(txt);  tags.append(tag)\n",
    "    for tup in c:   tagged_corpus.append(tup)\n",
    "tagged_corpus = list(set(tagged_corpus)) # removing duplicates\n",
    "n_grams = []; tokens = []\n",
    "for t in tags:\n",
    "    tkns = tokenize(t)\n",
    "    for t in tkns:  tokens.append(t)\n",
    "    n_gram = get_n_grams(t, tokens)\n",
    "    for n in n_gram:  n_grams.append(n)\n",
    "n_grams = list(set(n_grams))\n",
    "for t in set(tokens):  n_grams.append((t, t))\n",
    "tokens = list(set(tokens)); words = list(set(' '.join(text).split(' ')))\n",
    "tag_transition_matrix = get_conditional_prob(' '.join(tags), n_grams)\n",
    "emission_prob = get_emission_prob(corpus_tag, tagged_corpus)\n",
    "transition_prob = format_dict(tag_transition_matrix)\n",
    "emission_prob = format_dict(emission_prob); start_prob = get_start_prob(transition_prob)\n",
    "hmm_model = {'Q': tokens,'A': transition_prob,'O': words,'B': emission_prob,'q0': '<start>','qF': '</end>','start_prob': start_prob}\n",
    "if not os.path.isfile('hmm1.pickle'):  \n",
    "    with open('hmm1.pickle', 'wb') as f:pickle.dump(hmm_model, f)\n",
    "    with open('hmm1.pickle', 'rb') as f: hmm = pickle.load(f)\n",
    "pprint(hmm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dptable(V):\n",
    "    s = \"    \" + \" \".join((\"%7d\" % i) for i in range(len(V))) + \"\\n\"\n",
    "    for y in V[0]:  s += \"%.7s: \" % y;  s += \" \".join(\"%4s\" % (\"%f\" % v[y]) for v in V); s += \"\\n\"\n",
    "    print(s)\n",
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}];  path = {}\n",
    "    for y in states:\n",
    "        V[0][y] = start_p[y] * emit_p[y][obs[0]];   path[y] = [y]\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({});  newpath = {}\n",
    "        for y in states:\n",
    "            (prob, state) = max((V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states)\n",
    "            V[t][y] = prob\n",
    "            newpath[y] = path[state] + [y]\n",
    "        path = newpath\n",
    "    print_dptable(V);   (prob, state) = max((V[t][y], y) for y in states)\n",
    "    return (prob, path[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0       1\n",
      "<start>: 0.000000 0.000000\n",
      "</end>: 0.000000 0.000000\n",
      "cat: 0.000000 0.093750\n",
      "dog: 0.750000 0.093750\n",
      "\n",
      "(0.09375, ['dog', 'dog'])\n"
     ]
    }
   ],
   "source": [
    "with open('hmm1.pickle', 'rb') as f:     hmm = pickle.load(f)\n",
    "states = tuple(hmm['Q']); observations = tuple(hmm['O']); start_probability = hmm['start_prob']\n",
    "transition_probability = hmm['A']\n",
    "for s in states:\n",
    "    val_keys = transition_probability[s].keys()\n",
    "    for s1 in states:\n",
    "        if s1 not in val_keys:\n",
    "            transition_probability[s][s1] = 0.0\n",
    "emission_probability = hmm['B']\n",
    "for s in states:\n",
    "    if s not in emission_probability:\n",
    "        emission_probability[s] = {}\n",
    "        for o in observations:  emission_probability[s][o] = 0.0\n",
    "for s in states:\n",
    "    val_keys = emission_probability[s].keys()\n",
    "    for o in observations:\n",
    "        if o not in val_keys:     emission_probability[s][o] = 0.0\n",
    "print(viterbi(observations,states,start_probability,transition_probability,emission_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
